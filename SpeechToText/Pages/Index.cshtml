@page
@model IndexModel
@{
    ViewData["Title"] = "Home page";
}

<div id="app" class="flex h-screen justify-center items-center">
    <div class="recorder-container pr-16 border-r border-gray-300 items-center">
        <div v-show="activeEffectWhileRecognizing">
            <div class="outer"></div>
            <div class="outer-2"></div>
        </div>
        <button @@click="startRecognizeOnceAsync" class="bg-red-600 hover:bg-red-700 text-white font-bold py-4 px-4 rounded-full shadow-lg focus:outline-none">
            <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-mic"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line><line x1="8" y1="23" x2="16" y2="23"></line></svg>
        </button>
    </div>

    <div class="ml-16 border border-gray-300 rounded py-2 px-2 shadow text-xl">
        <video id="video1" width="640" height="360" hidden muted>
            <source type="video/mp4"> Your browser does not support playing this Video
        </video>
          <video id="video2" width="640" height="360" hidden muted>
            	    <source type="video/mp4"> Your browser does not support playing this Video
            </video>
          <div>
            <canvas id="myCanvas" width="640" height="360"></canvas>
          </div>
        @* <ul> *@
        @*     <li v-for="speechResult in speechResults" class="flex flex-col py-3 border-b border-gray-200"> *@
        @*         <span><label class="text-orange-600 font-bold">Request:</label> {{ speechResult.request }}</span> *@
        @*         <span><label class="text-green-500 font-bold">Response:</label> {{ speechResult.response }}</span> *@
        @*     </li> *@
        @* </ul> *@
    </div>
</div>

@section Scripts {
    <script src="https://unpkg.com/vue/dist/vue.js"></script>
	<script src="https://unpkg.com/axios@0.2.1/dist/axios.min.js"></script>
	<!-- Speech SDK reference sdk. -->
    <script src="~/js/sdk/microsoft.cognitiveservices.speech.sdk.bundle-min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.1.1/howler.min.js"></script>

<script>
    new Vue({
        el: '#app',

        data: {
            speechSdk: null,
            subscriptionKey: "91c500abae924b559ee3c062b3c3b6d1",
            serviceRegion: "japaneast",

            activeEffectWhileRecognizing: false,
            speechResults: [],

            video1: null,
            video2: null,
            timerID: null,
            canvas: null,
	    	ctx: null,

	    	token: "@Model.Token",
        },

        methods: {
            startRecognizeOnceAsync() {
                this.activeEffectWhileRecognizing = true

                let speechConfig
                let self = this

                if (this.subscriptionKey === "") {
                    alert("Please enter your Microsoft Cognitive Services Speech subscription key!")
                    return
                }

                speechConfig = this.speechSdk.SpeechConfig.fromSubscription(this.subscriptionKey, this.serviceRegion)
                speechConfig.speechRecognitionLanguage = "en-US"

                let audioConfig = this.speechSdk.AudioConfig.fromDefaultMicrophoneInput()
                let recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig)

                let object = {}
                object['request'] = ""

                recognizer.recognizeOnceAsync(
                    function (result) {
                        self.activeEffectWhileRecognizing = false

                        object['request'] += result.text

                        axios.get('?handler=SpeechResponse&speechRequest=' + object['request'] ).then(response => {
                            object['response'] = response[0].responseText

							let voice = new Howl({
								src: [`?handler=Translate&content='${object['response']}&token=${self.token}`],
								format: ['mp3'],
								onload: () => {
									self.speechResults.push(object)
									self.readText(object['response'], voice.duration())

									recognizer.close()
									recognizer = undefined
								}
							})

                        })
                    },
                    function (err) {
                        self.activeEffectWhileRecognizing = false

                        object['request'] += err
                        object['response'] = "error response"

                        self.speechResults.push(object)
                        self.readText(object['response'])

                        recognizer.close()
                        recognizer = undefined
                })

            },

            readText(message, duration) {
				let speech = new Howl({
					src: [`?handler=Translate&content='${message}&token=${this.token}`],
					format: ['mp3'],
					sprite: {'blast': [0, (duration * 1000) - 800]},
					onplay: () => {
						this.stopTimer()
						this.video2[0].pause();
						this.video1[0].play();

						console.log('speech starts')
					},
					onend: () => {
						this.video2[0].play();
						this.video1[0].pause();

						this.stopTimer()

						console.log('speech ends')
					},
					onload: () => {
						speech.play('blast')
					}
				})
            },

			onVideoEnd() {
				//stop copying frames to canvas for the current video element
				this.stopTimer()

				this.video2[0].play()
			},

			drawImage(video) {
				//last 2 params are video width and height
				this.ctx.drawImage(video, 0, 0, 640, 360);
			},

			stopTimer() {
				window.clearInterval(this.timerID);
			},

	    	playVideoOnPromise() {
            	const playPromise = this.video2[0].play();

				if (playPromise !== null){
					this.stopTimer()
					playPromise.catch(() => { this.video2[0].play(); })
				}
	    	}
        },

        mounted() {
            this.video1 = $("#video1")
            this.video2 = $("#video2")

            this.canvas = $("#myCanvas")
            this.ctx = this.canvas[0].getContext("2d")

			this.video1.attr("src", "../content/talking-avatar-video-2.mp4");
			this.video2.attr("src", "../content/still-avatar-video-2.mp4");

			// copy the 1st video frame to canvas as soon as it is loaded
			this.video1.one("loadeddata", () => {
				this.drawImage(this.video1[0]);
			});

			this.video1.on("play", () => {
				this.timerID = window.setInterval(() => {
					this.drawImage(this.video1[0]);
				}, 10);
			});

			this.video2.on("play", () => {
				this.timerID = window.setInterval(() => {
					this.drawImage(this.video2[0]);
				}, 30);
			});

			this.playVideoOnPromise()
			// this.video1.on("ended", this.onVideoEnd);
		},

        created() {
			if (!!window.SpeechSDK) {
				this.speechSdk = window.SpeechSDK
			}
        }
    })
</script>
}
